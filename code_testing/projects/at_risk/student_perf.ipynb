{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4bae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954842b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Student_performance_data _.csv')\n",
    "\n",
    "df.head() ## Display the first few rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AtRisk\"] = (df[\"GPA\"] < 2.5) ##Compare every GPA to 2.5, return True/False\n",
    "df[\"AtRisk\"] = df[\"AtRisk\"].astype(int) ##True = 1, False = 0\n",
    "df[[\"GPA\", \"AtRisk\"]].head(10) ## Display first 10 rows of GPA and AtRisk columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f65e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'AtRisk'\n",
    "\n",
    "drop_cols = [\"StudentID\", \"GPA\", \"GradeClass\", \"AtRisk\"] ## Remove ID + target + columns that leak target info\n",
    "feature_cols = [cols for cols in df.columns if cols not in drop_cols] ## List of feature columns\n",
    "\n",
    "x = df[feature_cols]\n",
    "y = df[target]\n",
    "\n",
    "print(\"Features:\", feature_cols) ##sanity check\n",
    "print(\"X shape:\", x.shape, \"Y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fad13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, ##x = features, y = target\n",
    "    test_size = 0.2, ##80% train, 20% test\n",
    "    random_state = 42, ##radom seed for reproducibility. Consistency purposes = 42\n",
    "    stratify = y ##maintain same proportion of classes in train and test sets\n",
    ")\n",
    "\n",
    "print(\"Train:\", x_train.shape, \"Test:\", x_test.shape)\n",
    "print(\"AtRisk rate (train):\", y_train.mean(), \"AtRisk rate (test):\", y_test.mean())\n",
    "\n",
    "##The more closely the train mean and the test mean are, the better the representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeec5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps = [\n",
    "    [\"scaler\", StandardScaler()], ##Standardize features by removing the mean and scaling to unit variance\n",
    "    [\"clf\", LogisticRegression(max_iter = 2000)] ##Logistic Regression classifier with max iterations set to 2000\n",
    "])\n",
    "\n",
    "model.fit(x_train, y_train) ##Train the model\n",
    "\n",
    "##Pipeline - Every time daa goes in, do these steps in this order\n",
    "    ##Rescales numeric features so the are comparable. Each feature has mean = 0 and std = 1.\n",
    "    ##It learns a weighted formula and pushes through a sigmoid function to output a probability between 0 and 1.\n",
    "        ##Probability > 0.5 = AtRisk, otherwise not AtRisk\n",
    "        ##max_iter = 2000 prevents warning, makes training stable. It guess weights and improve them repeatedy until convergence.\n",
    "##Last line - Fits the scaler using only training data and trains the logistic regression model on the scaled training data. Prevent data leakage and honest evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test) ##Take students the model has never seen before and guess whether they are atRisk or not\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)) ##Put of all students, how many did we get right?\n",
    "##Remember that 70% students are atRisk, if a model always predict AtRis get 70%, so accuracy alone is not enough\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred)) ##Confusion matrix\n",
    "## [[TN, FP] --> True Negative - Correctly predicted notAtRisk, False Positive - Incorrectly predicted AtRisk (fine)\n",
    "##  [FN, TP]] --> False Negative - Incorrectly predicted notAtRisk (not fine), True Positive - Correctly predicted AtRisk\n",
    "\n",
    "print(\"\\nReport\", classification_report(y_test, y_pred)) ##Precision, recall, f1-score for each class\n",
    "##precision (1) - Of all students predicted AtRisk, how many were actually AtRisk?\n",
    "##recall (1) - Of all students who were actually AtRisk, how many did we correctly identify? - Low recall --> model misses struggling students\n",
    "##f1-score - Balance between precision and recall.\n",
    "\n",
    "##If recall for 1 is below 0.6, we need to fix it, if it's above 0.6, we are good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471013b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model.named_steps['clf'] ##Trained logistic regression model inside the pipeline\n",
    "weights = pd.Series(clf.coef_[0], index=feature_cols).sort_values() \n",
    "##clf.coef_[0] is the weight of each feature in the same order as the feature_cols list\n",
    "##pd.Series labels each weight with the feature name so easier to read\n",
    "##.sort_values() sorts the weights in ascending order, negative weigts are features that decrease the likelihood of being AtRisk\n",
    "\n",
    "weights.sort_values().head(10) ## Which features most strongly reduce the chance at being atRisk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_student = x_test.iloc[[0]] ## Selects one row from the test set. [[0]] keeps it as a df not a series, 2d array [rows, features]\n",
    "pred = model.predict(one_student)[0] ##Predict whether the student is atRisk or not\n",
    "prob = model.predict_proba(one_student)[0][pred] \n",
    "## model.predict_proba returns a 2d array with the probability of each class for each student. [[prob_class_0, prob_class_1]\n",
    "## [0] gets the [[prob_class_0, prob_class_1] for the first student in the test set\n",
    "## [pred] gets the probability of the predicted class (1 or 0). If pred = 1, get prob_class_1, if pred = 0, get prob_class_0\n",
    "\n",
    "print(\"Prediction (1 = AtRisk; 0 = Not AtRisk):\", pred)\n",
    "print(\"Risk Probability:\", prob)\n",
    "print(\"\\nStudent Features:\\n\", one_student)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
